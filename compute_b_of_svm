import numpy as np
from cvxopt import matrix, solvers

# Define a simple linear kernel function
def linear_kernel(x1, x2):
    return np.dot(x1, x2)

# Define the SVM class
class SVM:
    def __init__(self, C=1.0):
        self.C = C
    
    def fit(self, X, y):
        n_samples, n_features = X.shape

        # Compute the Gram matrix (kernel matrix)
        K = np.zeros((n_samples, n_samples))
        for i in range(n_samples):
            for j in range(n_samples):
                K[i, j] = linear_kernel(X[i], X[j])

        # Setup the quadratic programming problem
        P = matrix(np.outer(y, y) * K)
        q = matrix(-np.ones(n_samples))
        G = matrix(np.vstack((-np.eye(n_samples), np.eye(n_samples))))
        h = matrix(np.hstack((np.zeros(n_samples), np.ones(n_samples) * self.C)))
        A = matrix(y, (1, n_samples), 'd')
        b = matrix(0.0)

        # Solve the quadratic programming problem
        solvers.options['show_progress'] = False
        solution = solvers.qp(P, q, G, h, A, b)

        # Get the Lagrange multipliers
        alphas = np.ravel(solution['x'])

        # Support vectors have non-zero lagrange multipliers
        sv = alphas > 1e-5
        self.alpha = alphas[sv]
        self.support_vectors = X[sv]
        self.support_vector_labels = y[sv]

        # Compute the intercept (bias term)
        self.b = 0
        for i in range(len(self.alpha)):
            self.b += self.support_vector_labels[i]
            self.b -= np.sum(self.alpha * self.support_vector_labels * K[sv][:,i])
        self.b /= len(self.alpha)
    
    def predict(self, X):
        y_predict = np.dot(X, self.w) + self.b
        return np.sign(y_predict)

# Example usage
if __name__ == "__main__":
    # Sample data (linearly separable)
    X = np.array([[2, 3], [3, 3], [5, 6], [6, 6], [8, 8], [9, 9]])
    y = np.array([1, 1, -1, -1, -1, -1])

    # Train the SVM
    svm = SVM(C=1.0)
    svm.fit(X, y)

    # Print the bias term
    print("Bias term b:", svm.b)
